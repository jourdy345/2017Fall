%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Structured General Purpose Assignment
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when 
% writing assignment content.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}
\usepackage{kotex}
\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage{graphicx} % Required to insert images
%\usepackage{subcaption}
\usepackage{amsmath,amsfonts,amsthm,amssymb} % Math packages
\usepackage{centernot}
\usepackage{sectsty} % Allows customizing section commands
\usepackage{newtxtext}
% \usepackage[lite,nofontinfo,zswash,straightbraces]{mtpro2}
\usepackage{bm}
% \usepackage{times,mathptmx}
\usepackage{tabto}
\usepackage{titlesec}
\usepackage[shortlabels]{enumitem}
\usepackage{booktabs}
\usepackage{subfig}
\usepackage{cancel}

\DeclareMathOperator*{\argmax}{\arg\!\max}
\newtheorem*{theorem}{Theorem}
\newtheorem*{proposition}{Proposition}

\newcommand{\indep}{\rotatebox[origin=c]{90}{$\models$}}
\newcommand\textline[4][t]{%
  \par\smallskip\noindent\parbox[#1]{.333\textwidth}{\raggedright\texttt{+}#2}%
  \parbox[#1]{.333\textwidth}{\centering#3}%
  \parbox[#1]{.333\textwidth}{\raggedleft\texttt{#4}}\par\smallskip%
}

%--------------------------------------------------------------------------------
%KNITR
%---------------------------------------------------------------------------
\usepackage[]{color}
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{0.96\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
%--------------------------------------------------------------------------------------------------

%Roman Numeral
\makeatletter
\newcommand*{\rom}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in 

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkAuthorName} % Top left header
\chead{\hmwkClass\ (\hmwkClassInstructor\ \hmwkClassTime): \hmwkTitle} % Top center header
\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
\section{\homeworkProblemName} % Make a section in the document with the custom problem count
\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}
   
%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Assignment \#2} % Assignment title
\newcommand{\hmwkDueDate}{Wednesday,\ Sep\ 27,\ 2017} % Due date
\newcommand{\hmwkClass}{STAT232} % Course/class
\newcommand{\hmwkClassTime}{3:30pm} % Class/lecture time
\newcommand{\hmwkClassInstructor}{Taeryon Choi} % Teacher/lecturer
\newcommand{\hmwkAuthorName}{B. Park \& D. Lim} % Your name

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------
%title_page_1.tex와 연동
%\title{
%\vspace{2in}
%\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
%\normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
%\vspace{0.1in}\large{\textit{\hmwkClassInstructor\ \hmwkClassTime}}
%\vspace{3in}
%}

%\author{\textbf{\hmwkAuthorName}}
%\date{} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}
%\input{./title_page_1.tex}%TITLE PAGE
%\maketitle
\newpage

\begin{minipage}{\columnwidth}
\centering
\textbf{{\LARGE Solutions for Assignment \#2 : Mathematical Statistics}}

\vspace{15pt}
{\Large Beomjo Park \& Daeyoung Lim}

Dept. of Statistics, Korea University
\end{minipage}
%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

% To have just one problem per page, simply put a \clearpage after each problem
\begin{homeworkProblem}
Let $(Y_1, Y_2)$ denote the coordinates of a point chosen at random inside a unit circle whose center is at the origin. That is, $Y_1$ and $Y_2$ have a joint density function given by
\begin{align*}
  f(y_1, y_2) = \begin{cases}
    \frac{1}{\pi}, & y_1^2 + y_2^2 \le 1,\\
    0, & \text{elsewhere.}
  \end{cases}
\end{align*}

Find $P(Y_1 \le Y_2)$.\\

\begin{problemAnswer} {
\emph{(Method 1)}
  Directly dealing with the circle on the Cartesian plane, we should divide the integration region.
  \begin{equation}
  \begin{split}
      P(Y_{1}\leq Y_{2}) &= \int_{-\sqrt{2}/2}^{\sqrt{2}/2}\int_{-\sqrt{1-x^{2}}}^{x}\dfrac{1}{\pi}\,\mathrm{d}y\,\mathrm{d}x + \int_{\sqrt{2}/2}^{1}\int_{-\sqrt{1-x^{2}}}^{\sqrt{1-x^{2}}}\dfrac{1}{\pi}\,\mathrm{d}y\,\mathrm{d}x\\
      &= \dfrac{1}{2\pi}+\dfrac{1}{4} +\dfrac{1}{4}-\dfrac{1}{2\pi} = \dfrac{1}{2}
  \end{split}
    \end{equation}  

\emph{(Method 2)}

  The problem is equivalent to calculating $P(Y_{1}-Y_{2}\leq 0)$ and since the integration region is a circle on the $xy$-plane, it is more comfortable to use the polar coordinate where 
  \begin{equation}
  \begin{split}
    x &= r\cos\theta\\
    y &= r\sin\theta
  \end{split}
  \end{equation}
  The Jacobian term for the transformation becomes
  \begin{equation}
    |J| = \det \begin{pmatrix}
      \cos\theta & \sin\theta\\
      -r\sin\theta & r\cos\theta
    \end{pmatrix} = r
  \end{equation}
  The region satisfying
  \begin{equation}
    y_{1}\leq y_{2} \quad \text{and}\quad y_{1}^{2}+y_{2}^{2}\leq 1
  \end{equation}
  is the circle below the line $y_{2}=y_{1}$. Thus, the integration region for $r$ is obvious, $0\leq r \leq 1$, and the integration region for $\theta$ varies depending on where you start drawing the circle. Assume $\theta \in (-\pi,\pi)$. Then
  \begin{equation}
  \begin{split}
    P(Y_{1}\leq Y_{2}) &= \int_{-3\pi/4}^{\pi/4}\int_{0}^{1}\dfrac{r}{\pi}\,\mathrm{d}r\,\mathrm{d}\theta\\
    &= \int_{-3\pi/4}^{\pi/4}\dfrac{1}{2\pi}\,\mathrm{d}\theta\\
    &= \dfrac{1}{2}
  \end{split}
  \end{equation}

  \emph{(Method 3)}

  Intuitively, the answer is trivially $1/2$ since the probability density is uniform on the circle and the integration region is exactly half the circle.
}\end{problemAnswer}

\end{homeworkProblem}

%----------------------------------------------------------------------------------------
% PROBLEM 2
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
Let $(X,Y)$ have a uniform distribution over the unit square, i.e. the joint p.d.f. of $(X,Y)$ is given by
\begin{align}
	f(x,y) = \begin{cases}
    1 & 0\le x\le 1,\ 0\le y\le 1\\
    0, & \text{otherwise}
  \end{cases}
\end{align}

Find the moment generating function $Z=-\log(X)-\log(Y)$.

\begin{problemAnswer}{
\emph{(Method 1)}
  
  \begin{equation}
    \begin{split}
      \operatorname{E}(e^{tZ}) &= \operatorname{E}(e^{t(-\log X - \log Y)}) = \operatorname{E}\left[(XY)^{-t}\right]\\
      &= \int_{0}^{1}\int_{0}^{1}(xy)^{-t}\,\mathrm{d}x\,\mathrm{d}y = \int_{0}^{1}y^{-t}\left(\left.\dfrac{x^{1-t}}{1-t}\right|_{0}^{1}\right)\,\mathrm{d}y\\
      &= \int_{0}^{1}\dfrac{y^{-t}}{1-t}\,\mathrm{d}y = \left.\dfrac{y^{1-t}}{(1-t)^{2}}\right|_{0}^{1} = \dfrac{1}{(t-1)^{2}}\,\quad t < 1
    \end{split}
  \end{equation}

  \emph{(Method 2)}
  
  Note that the given function is the joint PDF of two independent standard uniform random variables, that is, $X,Y \overset{\text{iid}}{\sim}\operatorname{Unif}(0,1)$. Thus, we can use the relations
  \begin{itemize}
    \item $-\log U \sim \operatorname{Exp}(1)$ where $U\sim \operatorname{Unif}(0,1)$.
    \begin{proof}
      Let $g(u) = -\log u$. Then, $g^{-1}(x) = e^{-x}$. By the variable transformation,
      \begin{equation}
        f_{X}(x) = f_{U}(g^{-1}(x))\left|\dfrac{d g^{-1}(x)}{dx}\right| = e^{-x}
      \end{equation}
      which is the density of the exponential distribution with mean $1$.
    \end{proof}
    \item If $E_{1},E_{2}\overset{\text{iid}}{\sim}\operatorname{Exp}(1)$, $E_{1}+E_{2}\sim \operatorname{Gamma}(2,1)$.
    \begin{proof}
      Using the convolution, set $Z = E_{1}+E_{2}$, 
      \begin{equation}
      \begin{split}
        f_{Z}(z) &= \int_{-\infty}^{\infty}f_{E_{1}}(z-e_{2})f_{E_{2}}(e_{2})\,\mathrm{d}e_{2}\\
          &= \int_{0}^{z}e^{-(z-e_{2})}e^{-e_{2}}\,\mathrm{d}e_{2},\qquad\qquad (\because z-e_{2}>0)\\
          &= \int_{0}^{z}e^{-z}\,\mathrm{d}e_{2}\\
          &= ze^{-z}
      \end{split}
      \end{equation}
    \end{proof}
  \end{itemize}

  Thus, the MGF of $Z \sim \operatorname{Gamma}(2,1)$ becomes
  \begin{equation}
    \begin{split}
      \operatorname{E}(e^{tZ}) &= \int_{0}^{\infty}ze^{(t-1)z}\,\mathrm{d}z\\
      &= \dfrac{1}{(t-1)^{2}},\quad t<1
    \end{split}
  \end{equation}
}\end{problemAnswer}

\end{homeworkProblem}


%----------------------------------------------------------------------------------------
%	PROBLEM 3
%----------------------------------------------------------------------------------------
\newpage

\begin{homeworkProblem}
Let $Y$ have a distribution function given by
\[
F(y) = \begin{cases}
	0, 			& y < 0\\
	1-e^{-y^2},	& y \ge 0
\end{cases}
\]

Find a transformation $G(U)$ such that, if $U$ has a uniform distribution on the interval $(0,1)$, $G(U)$ has the same distribution as $Y$.\\

\begin{problemAnswer} {
\emph{(Method 1)}

  Let $X = G(U)$. Then
  \begin{equation}
      P(X\leq x) = P(G(U)\leq x) = P(U\leq G^{-1}(x)) = G^{-1}(x)\quad (\because F_{U}(u)=u)
  \end{equation}
  Thus, $F = G^{-1}\implies G = F^{-1}$.
  \begin{equation}
    F^{-1}(u) = \sqrt{-\log(1-u)}  
  \end{equation}

\emph{(Method 2)}

	This is called the \emph{probability integral transform} which states that we can sample a random variable by plugging a standard uniform random variable $U$ into the \emph{quantile function} or the \emph{inverse CDF} of the desired distribution. That is, $F^{-1}(U) \sim F$.
	\begin{proof}
		Let $U \sim \operatorname{Unif}(0,1)$ and $F$ be the distribution function that we want to sample from. If we define $Y = F^{-1}(U)$,
		\begin{equation}
			\begin{split}
				P(Y\leq y) &= P(F^{-1}(U)\leq y)\\
				&= P(U \leq F(y))\quad (\text{F is bijective})\\
				&= F(y)
			\end{split}
		\end{equation}
		Thus, the CDF of the newly defined variable $F^{-1}(U)$ recovers the CDF of interest.
	\end{proof}
	Then, we now know that $G = F^{-1}$ where
	\begin{equation}
		F^{-1}(u) = \sqrt{-\log(1-u)}
	\end{equation}

}\end{problemAnswer}

\end{homeworkProblem}

%----------------------------------------------------------------------------------------
% PROBLEM 4
%----------------------------------------------------------------------------------------
\newpage
\begin{homeworkProblem}
Let $Y_1, Y_2, \ldots, Y_n$ be independent Poisson random variables with means $\lambda_1, \lambda_2, \ldots, \lambda_n$, respectively. Find the

(a) probability function of $\sum_{i=1}^n Y_i$.\\

\begin{problemAnswer} {
Note that the moment generating function (MGF) of $Y_i$ is
\[
M_{Y_i} (t) = \exp \left( \lambda_i (\exp(t) - 1) \right)
\]
Then,
\begin{align*}
M_{\sum_{i=1}^n Y_i} (t) &= E \left( \exp \left(t \sum_{i=1}^n Y_i \right) \right) =  E \left( \prod_{i=1}^n \exp (t Y_i) \right) = \prod_{i=1}^n E \left( \exp (t Y_i) \right)	&\left( \because~ \forall Y_i : \text{ind} \right)\\
		&= \prod_{i=1}^n M_{Y_i} (t) = \exp \left( \sum_{i=1}^n \lambda_i (\exp(t) - 1) \right)
\end{align*}

By the uniqueness theorem of MGF,
\[
\sum_{i=1}^n Y_i \sim \operatorname{Poi} \left( \sum_{i=1}^n \lambda_i \right)
\]
}\end{problemAnswer}


(b) conditional probability function of $Y_1$, given that $\sum_{i=1}^n Y_i = m$.\\

\begin{problemAnswer} {
\begin{proposition}
	If $X_i \overset{ind}{\sim} \operatorname{Poi} (\lambda_i), (i=1,2)$, then given $X_1 + X_2=m$, $X_1 \mid (X_1 + X_2 =m) \sim \operatorname{Binom} \left( m, \frac{\lambda_1}{\lambda_1 + \lambda_2} \right)$
\end{proposition}
\begin{proof}
	Note that $X_1 + X_2 \sim \operatorname{Poi} (\lambda_1 + \lambda_2)$ by (a).
	\begin{align*}
		P(X_1 = s | X_1 + X_2 = m) &= \frac{P \left( (X_1 = s) \cap (X_1 + X_2 = m) \right)}{P(X_1 + X_2 = m)} = \frac{P \left( (X_1 = s) \cap (X_2 = m - s) \right)}{P(X_1 + X_2 = m)} \\
			&= \frac{P \left( X_1 = s \right) P \left( X_2 = m - s \right)}{P(X_1 + X_2 = m)}	&(\because X_1 \indep X_2)\\
			&= \frac{\lambda_1^s e^{-\lambda_1}}{s!} \frac{\lambda_2^{(m-s)} e^{-\lambda_2}}{(m-s)!} \frac{m!}{(\lambda_1 + \lambda_2)^m e^{-(\lambda_1 + \lambda_2)}}\\
			&= \frac{m!}{s! (m-s)!} \left( \frac{\lambda_1}{\lambda_1 + \lambda_2} \right)^s \left( \frac{\lambda_2}{\lambda_1 + \lambda_2} \right)^{m-s}, \quad (s=0,\cdots,m)
	\end{align*}
\end{proof}

Take $X_1 = Y_1$, and $X_2 = \sum_{i=2}^n Y_i \sim \operatorname{Poi} \left( \sum_{i=2}^n \lambda_i \right)$ by (a). Then $X_1 \mid (X_{1} + X_{2} = m) \sim \operatorname{Binom} \left( m, \frac{\lambda_1}{\sum_{i=1}^n \lambda_i} \right)$.

}\end{problemAnswer}

(c) conditional probability function of $Y_1 + Y_2$ given that $\sum_{i=1}^n Y_i = m$.\\

\begin{problemAnswer} {
Take $X_1 = Y_1 + Y_2 \sim \operatorname{Poi} (\lambda_1 + \lambda_2)$ by (a), and $X_2 = \sum_{i=3}^n Y_i \sim \operatorname{Poi} \left( \sum_{i=3}^n \lambda_i \right)$ by (a).
From (b),
\[
	Y_1 + Y_2 \mid \sum_{i=1}^n Y_i = m \sim \operatorname{Binom} \left(m, \frac{\lambda_1 + \lambda_2}{\sum_{i=1}^n \lambda_i} \right)
\]
}\end{problemAnswer}

\end{homeworkProblem}

\newpage
%----------------------------------------------------------------------------------------
% PROBLEM 5
%----------------------------------------------------------------------------------------
\begin{homeworkProblem}
Suppose that $W = Y_1 + Y_2$ where $Y_1$ and $Y_2$ are independent. If $W$ has a $\chi^2$ distribution with $\nu$ degrees of freedom and $Y_1$ has a $\chi^2$ distribution with $\nu_1 < \nu$ degrees of freedom, show that $Y_2$ has a $\chi^2$ distribution with $\nu - \nu_1$ degrees of freedom.\\

\begin{problemAnswer} {
	Since we do not yet know whether $W \indep Y_{1}$, it is impossible to use the convolution. Therefore, we should use the MGF instead.
  \begin{equation}
    \begin{split}
      \operatorname{E}\left(e^{tW}\right) &= \operatorname{E}\left(e^{t(Y_{1}+Y_{2})}\right)\\
      &= \operatorname{E}\left(e^{tY_{1}}\right)\operatorname{E}\left(e^{tY_{2}}\right)
    \end{split}
  \end{equation}
  If we explicitly compute the MGF of $X\sim  \chi^{2}$-distribution with $r$ degrees of freedom,
  \begin{equation}
  \begin{split}
    \operatorname{E}(e^{tX}) &= \int_{0}^{\infty} e^{tx} \dfrac{(1/2)^{r/2}}{\Gamma(r/2)}x^{r/2 - 1}\exp\left(-\dfrac{1}{2}x\right)\,\mathrm{d}x\\
    &= \int_{0}^{\infty} \dfrac{(1/2)^{r/2}}{\Gamma(r/2)}x^{r/2 - 1}\exp\left\{-\left(\dfrac{1}{2}-t\right)x\right\} \,\mathrm{d}x\\
    &= \dfrac{(1/2)^{r/2}}{(1/2-t)^{r/2}} \underbrace{\int_{0}^{\infty}\dfrac{(1/2-t)^{r/2}}{\Gamma(r/2)}x^{r/2-1}\exp\left\{-\left(\dfrac{1}{2}-t\right)x\right\} \,\mathrm{d}x}_{=1}\\
    &= \left(\dfrac{1}{1-2t}\right)^{r/2},\quad t < \dfrac{1}{2}
  \end{split}
  \end{equation}
  Therefore, 
  \begin{equation}
  \begin{split}
    \operatorname{E}\left(e^{tY_{2}}\right) &= \operatorname{E}\left(e^{tW}\right) / \operatorname{E}\left(e^{tY_{1}}\right)\\
        &= (1 - 2t)^{-\nu/2} / (1-2t)^{-\nu_{1}/2}\\
        &= (1-2t)^{-(\nu-\nu_{1})/2},\quad t < \dfrac{1}{2}
  \end{split}
  \end{equation}
  Since the MGF completely determines the distribution if it exists, the MGF of $Y_{2}$ is of a $\chi^{2}$-distribution with $\nu-\nu_{1}$ degrees of freedom.
}\end{problemAnswer}

\end{homeworkProblem}

%----------------------------------------------------------------------------------------
% PROBLEM 7
%----------------------------------------------------------------------------------------
\newpage
\begin{homeworkProblem} [Problem 7]
Suppose that $Y_1$ and $Y_2$ are independent exponentially distributed random variables, both with mean $\beta$, and define $U_1 = Y_1 + Y_2$ and $U_2 = Y_1 / Y_2$.

a. Show that the joint density of $(U_1, U_2)$ is
\[
f_{U_1, U_2} (u_1, u_2) = \begin{cases}
	\frac{1}{\beta^2} u_1 e^{- u_1 / \beta} \frac{1}{(1+u_2)^2},	& 0 < u_1,~ 0 < u_2\\
	0,	& \text{otherwise.}
\end{cases}
\]

\begin{problemAnswer} {
Note that the joint probability distribution of $(Y_{1},Y_{2})$ is
\begin{equation}
	f_{Y_{1},Y_{2}}(y_{1},y_{2}) = \dfrac{1}{\beta^{2}}\exp\left(-\dfrac{y_{1}+y_{2}}{\beta}\right)
\end{equation}
The inverse relations are
\begin{equation}
	\begin{split}
		y_{1} &= \dfrac{u_{1}u_{2}}{1+u_{2}}\\
		y_{2} &= \dfrac{u_{1}}{1+u_{2}}
	\end{split}
\end{equation}
and the Jacobian is 
\begin{equation}
	|J| = \left|\det \begin{pmatrix}
		u_{2}/(1 + u_{2}) & 1 / (1 + u_{2})\\
		u_{1} / (1 + u_{2})^{2} & -u_{1} / (1 + u_{2})^{2}
	\end{pmatrix}\right| = \dfrac{u_{1}}{(1 + u_{2})^{2}}
\end{equation}
Using the change of variable,
\begin{equation}
\begin{split}
	f_{U_{1},U_{2}}(u_{1},u_{2}) &= f_{Y_{1},Y_{2}}(y_{1},y_{2})|J|\\
	&= \dfrac{1}{\beta^{2}}\exp\left(-\dfrac{u_{1}}{\beta}\right)\dfrac{u_{1}}{(1+u_{2})^{2}}\\
	 &= \left(\dfrac{1}{\beta^{2}}u_{1}\exp\left(-\dfrac{u_{1}}{\beta}\right) \right)\times \left(\dfrac{1}{(1+u_{2})^{2}} \right), \quad u_{1}>0,\;u_{2}>0
\end{split}
\end{equation}
}\end{problemAnswer}

b. Are $U_1$ and $U_2$ are independent? Why?

\begin{problemAnswer} {
The joint probability distribution of $(U_{1},U_{2})$ is separable, that is,
\begin{equation}
	\begin{split}
		f_{U_{1},U_{2}}(u_{1},u_{2}) &= \operatorname{Gamma}\left(U_{1}\,|\,2, \dfrac{1}{\beta}\right)\times \left(\dfrac{1}{(1+u_{2})^{2}}\right), \quad u_{1}>0, u_{2}>0
	\end{split}
\end{equation}
It is clear that the gamma distribution component is a valid density. We should check if $1/(1+x)^{2}$ is a valid probability density function as well.
\begin{equation}
	\int_{0}^{\infty}\dfrac{1}{(1+x)^{2}}\,\mathrm{d}x = \left. -\dfrac{1}{1+x}\right|_{0}^{\infty} = 1
\end{equation}
It satisfies the conditions for a probability densify function. Thus, they are independent.
}\end{problemAnswer}

\end{homeworkProblem}


%----------------------------------------------------------------------------------------
% PROBLEM 8
%----------------------------------------------------------------------------------------

% \begin{homeworkProblem} [Problem 8]

% Let $X_r$ be a r.v. distributed as $t$ with $r (\ge 3)$ degrees of freedom : $X_r \sim t_r$. Compute $E(X_r^2)$.\\

% \begin{problemAnswer} {
% Note that
% \[
% X_r \equiv \frac{Z}{\sqrt{W / r}}, \quad Z \sim \operatorname{N} (0,1) ~\indep~ W \sim \chi^2(r)
% \]
% Then,
% \begin{align*}
% 	\operatorname{E}(X_r^2) &= \operatorname{E}\left( \frac{Z^2}{W / r} \right) = r \times \operatorname{E}\left( Z^2 \right) \operatorname{E}\left( \frac{1}{W} \right)		&\left( \because Z^2 \indep 1/W \right)\\
% 			 &= r \times  \operatorname{E}\left( \frac{1}{W} \right) = \frac{r}{r-2}	&\left( \because Z^2 \sim \chi^2 (1) \right)\\
% \end{align*}

% From the fact that
% \begin{align*}
% 	\operatorname{E}\left( \frac{1}{W} \right) &= \int_0^\infty \frac{1}{w} \frac{1}{2^{r/2} \Gamma(r/2)} w^{r/2 - 1} e^{- w/2} dw 
% 		= \frac{1}{2 \cdot (r/2 - 1)} \underbrace{\int_0^\infty \frac{1}{2^{(r-2)/2} \Gamma((r-2)/2)} w^{(r-2)/2 - 1} e^{- w/2} dw}_{ = 1}\\
% 		&= \frac{1}{r-2}
% \end{align*}
% }\end{problemAnswer}

% \end{homeworkProblem}
%------------------------------------
%\bibliographystyle{apalike}
%\bibliography{Hw1}
\end{document}