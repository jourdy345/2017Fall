%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Structured General Purpose Assignment
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when 
% writing assignment content.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}
\usepackage{kotex}
\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage{graphicx} % Required to insert images
%\usepackage{subcaption}
\usepackage{amsmath,amsfonts,amsthm,amssymb} % Math packages
\usepackage{centernot}
\usepackage{sectsty} % Allows customizing section commands
\usepackage{newtxtext}
\usepackage[lite,nofontinfo,zswash,straightbraces]{mtpro2}
\usepackage{bm}
% \usepackage{times,mathptmx}
\usepackage{tabto}
\usepackage{titlesec}
\usepackage[shortlabels]{enumitem}
\usepackage{booktabs}
\usepackage{subfig}
\usepackage{cancel}
\usepackage{mathtools}

\DeclareMathOperator*{\argmax}{\arg\!\max}
\newtheorem*{theorem}{Theorem}

\newcommand{\indep}{\rotatebox[origin=c]{90}{$\models$}}
\newcommand\textline[4][t]{%
  \par\smallskip\noindent\parbox[#1]{.333\textwidth}{\raggedright\texttt{+}#2}%
  \parbox[#1]{.333\textwidth}{\centering#3}%
  \parbox[#1]{.333\textwidth}{\raggedleft\texttt{#4}}\par\smallskip%
}

%--------------------------------------------------------------------------------
%KNITR
%---------------------------------------------------------------------------
\usepackage[]{color}
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{0.96\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
%--------------------------------------------------------------------------------------------------

%Roman Numeral
\makeatletter
\newcommand*{\rom}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in 

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkAuthorName} % Top left header
\chead{\hmwkClass\ (\hmwkClassInstructor\ \hmwkClassTime): \hmwkTitle} % Top center header
\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
\section{\homeworkProblemName} % Make a section in the document with the custom problem count
\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}
   
%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Assignment \#1} % Assignment title
\newcommand{\hmwkDueDate}{Thursday,\ Mar\ 17,\ 2017} % Due date
\newcommand{\hmwkClass}{STAT412} % Course/class
\newcommand{\hmwkClassTime}{5:00pm} % Class/lecture time
\newcommand{\hmwkClassInstructor}{Taeryon Choi} % Teacher/lecturer
\newcommand{\hmwkAuthorName}{D. Lim} % Your name

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------
%title_page_1.tex와 연동
%\title{
%\vspace{2in}
%\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
%\normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
%\vspace{0.1in}\large{\textit{\hmwkClassInstructor\ \hmwkClassTime}}
%\vspace{3in}
%}

%\author{\textbf{\hmwkAuthorName}}
%\date{} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}
%\input{./title_page_1.tex}%TITLE PAGE
%\maketitle
\newpage

\begin{minipage}{\columnwidth}
\centering
\textbf{{\LARGE Solutions for Assignment \#1 : Topics in Mathematical Statistics}}

\vspace{15pt}
{\Large Daeyoung Lim}

Dept. of Statistics, Korea University
\end{minipage}
%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

% To have just one problem per page, simply put a \clearpage after each problem
\begin{homeworkProblem}
Suppose that $k$ events $B_1,\ldots,B_k$ form a partition of the sample space $\Omega$. For $i=1,\ldots,k$, let $P(B_i)$ denote the prior probability of $B_i$. Also, for each event $A$ such that $P(A)>0$, let $P(B_i |A)$ denote the posterior probability of $B_i$ given that the event $A$ has occurred. Prove that if $P(B_1|A) < P(B_1)$, then $P(B_i|A) > P(B_i)$ for at least one value of $i$ ($i=2,\ldots,k)$.\\
\begin{problemAnswer}{
  Recall that
  \begin{equation}
    \sum_{i=1}^{k}P(B_{i}) = 1\quad\text{and}\quad \sum_{i=1}^{k}P(B_{i}\mid A)=1
  \end{equation}
  \emph{(Proof by contradiction)} Suppose that $P(B_{i}\mid A) < P(B_{i}), \forall i=1,\ldots,k$. Then
  \begin{equation}
    \sum_{i=1}^{k}P(B_{i}\mid A) < \sum_{i=1}^{k}P(B_{i}) \qquad (= 1 < 1)
  \end{equation}
  Thus, contradiction.
}
\end{problemAnswer}

\end{homeworkProblem}

%----------------------------------------------------------------------------------------
% PROBLEM 2
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
Suppose that a box contains five coins, and that for each coin there is a different probability that a head will be obtained when the coin is tossed. Let $p_i$ denote the probability of a head when the $i$th coin is tossed ($i=1,\ldots,5)$, and suppose that $p_1=0,p_2=1/4,p_3=1/2,p_4=3/4$, and $p_5=1$.

(a) Suppose that one coin is selected at random from the box and when it is tossed once, a head is obtained. What is the posterior probability that the $i$th coin was selected $(i=1,\ldots,5)$?\\
\begin{problemAnswer}{

} \end{problemAnswer}
(b) If the same coin were tossed again, what would be the probability of obtaining another head?\\
\begin{problemAnswer}{
  
}\end{problemAnswer}
(c) If a tail had been obtained on the first toss of the selected coin and the same coin were tossed again,
what would be the probability of obtaining a head on the second toss?\\
\begin{problemAnswer}{
  
}\end{problemAnswer}

\end{homeworkProblem}
%----------------------------------------------------------------------------------------
%	PROBLEM 3
%----------------------------------------------------------------------------------------

\begin{homeworkProblem}
The \textit{skewness} of a random variable $X$ can be defined as  
     $\gamma_1 = \mu_3/(\mu_2)^{\frac{3}{2}}$ where
\[               \mu_n  =  {\rm E} (X  -  {\rm E} (X))^n \]
    
     Find the skewness of a random variable $X$ with a binomial
     distribution $B(n, \pi)$ of index $n$ and parameter $\pi$.\\
\begin{problemAnswer}{
  \emph{(Method 1: Direct calculation)}

  Expanding,
  \begin{equation}
    \begin{split}
      \operatorname{E}\left\{\left(X-\operatorname{E}(X)\right)^{3}\right\} &= \operatorname{E}\left(X^{3}-3n\pi X^{2}+3(n\pi)^{2}X - (n\pi)^{3}\right)\\
      &= \operatorname{E}(X^{3})-3n\pi\operatorname{E}(X^{2})+3n^{2}\pi^{2}\operatorname{E}(X)-n^{3}\pi^{3}
    \end{split}
  \end{equation}
  Since $\operatorname{E}(X)=n\pi$ and $\operatorname{E}(X^{2}) = n\pi(1-\pi+n\pi)$, $\operatorname{E}(X^{3})$ should be computed through MGF (or PGF).
  \begin{equation}
    M_{X}(t) = \operatorname{E}(e^{tX}) = \sum_{x=0}^{n}e^{tx}\binom{n}{x}\pi^{x}(1-\pi)^{n-x}=(1-\pi+e^{t}\pi)^{n}\quad (\because \text{Binominal theorem})
  \end{equation}
  Then
  \begin{equation}
    M_{X}^{(3)}(t)=\pi n e^{t}(\pi(e^{t}-1)+1)^{n-3}(\pi^{2}(n^{2}e^{2t}+(1-3n)e^{t}+1) + \pi((3n-1)e^{t}-2)+1)
  \end{equation}
  and
  \begin{equation}
    \operatorname{E}(X^{3}) = M_{X}^{(3)}(0) = \pi n(\pi^{2}(n-2)(n-1)+3\pi(n-1)+1)
  \end{equation}
  which yields
  \begin{equation}
    \mu_{3} = n\pi(1-\pi)(1-2\pi)
  \end{equation}
  Therefore,
  \begin{equation}
    \gamma_{1} = \dfrac{1-2\pi}{\sqrt{n\pi(1-\pi)}}
  \end{equation}

  \emph{(Method 2: Change of variable)}

  Consider $X \overset{D}{=} \sum_{i=1}^{n}Y_{i}$ where $Y_{i}\sim \operatorname{Bernoulli}(\pi)$. Thus
  \begin{equation}
    X-n\pi \overset{D}{=} \sum_{i=1}^{n}Y_{i}-n\pi = \sum_{i=1}^{n}(Y_{i}-\pi)
  \end{equation}
  If we again let $Z_{i}=Y_{i}-\pi$,
  \begin{equation}
    X-n\pi \overset{D}{=} \sum_{i=1}^{n}Z_{i},\quad\text{where }Z_{i}=\begin{cases}
      1-\pi, &\text{with $\pi$}\\
      -\pi, &\text{with $1-\pi$}
    \end{cases}
  \end{equation}
  Thus,
  \begin{equation}
    \begin{split}
      (X-n\pi)^{3} &= \left(\sum_{i=1}^{n}Z_{i}\right)^{3} = \sum_{i=1}^{n}Z_{i}^{3}+\sum_{i\neq j}Z_{i}^{2}Z_{j}+\sum_{i\neq j \neq k}Z_{i}Z_{j}Z_{k}\\
      \operatorname{E}\left\{(X-n\pi)^{3}\right\} &= \sum_{i=1}^{n}\operatorname{E}(Z_{i}^{3})=n\operatorname{E}(Z_{1}^{3})\qquad (\because Z_{i}\indep Z_{j}\;\forall i\neq j\;\;\text{and}\;\; \operatorname{E}(Z_{i})=0)\\
      &= n\pi(1-\pi)(1-2\pi)\implies \gamma_{1}=\dfrac{1-2\pi}{\sqrt{n\pi(1-\pi)}}
    \end{split}
  \end{equation}
} \end{problemAnswer}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------
% PROBLEM 4
%----------------------------------------------------------------------------------------
\begin{homeworkProblem}
Define
\[ I=\int_{0}^{\infty}\exp\left(-\dfrac{1}{2} z^2\right)\,\mathrm{d}z \]
     and show 
    that 
\[ I=\int_{0}^{\infty}\exp\left(-\dfrac{1}{2}(xy)^2\right)\,y\,\mathrm{d}x
    =\int_{0}^{\infty}\exp\left(-\dfrac{1}{2}(zx)^2\right)\,z\,\mathrm{d}x. \]
     Deduce that
\[ I^2=\int_{0}^{\infty}\int_{0}^{\infty}
        \exp\left\{-\dfrac{1}{2}(x^2+1)z^2\right\}\,z\,\mathrm{d}z\,\mathrm{d}x.             \]
   and % By substituting $(1+x^2)z^2=2t$ so that $z\,dz=dt/(1+x^2)$ 
  show that $I=\sqrt{\pi/2}$.
  %so that the density of the standard normal 
   %  distribution as defined in Section 1.3 does integrate to unity 
   %  and so is indeed a density.  
  (This method is due to Laplace, 1812, 
     Section 24.)\\

\begin{problemAnswer} {
  Using the transformation $z = yx$,
  \begin{equation}
    \mathrm{d}z = y\,\mathrm{d}x \implies \int_{0}^{\infty}\exp\left(-\dfrac{1}{2}z^{2}\right)\,\mathrm{d}z = \int_{0}^{\infty}\exp\left(-\dfrac{1}{2}(xy)^{2}\right)y\,\mathrm{d}x
  \end{equation}
  Since $y$ is just a dummy variable, we can replace it with $z$:
  \begin{equation}
    I = \int_{0}^{\infty}\exp\left(-\dfrac{1}{2}(zx)^{2}\right)z\,\mathrm{d}x
  \end{equation}
  Then
  \begin{equation}
    \begin{split}
      I^{2} &= \left(\int_{0}^{\infty}\exp\left(-\dfrac{1}{2}z^{2}\right)\,\mathrm{d}z\right)\left(\int_{0}^{\infty}\exp\left(-\dfrac{1}{2}(zx)^{2}\right)z\mathrm{d}x\right)\\
      &= \int_{0}^{\infty}\int_{0}^{\infty}\exp\left(-\dfrac{1}{2}(x^{2}+1)z^{2}\right)z\,\mathrm{d}z\,\mathrm{d}x
    \end{split}
  \end{equation}
  To evaluate the double integral, let
  \begin{equation}
  \begin{split}
    u = -\dfrac{1}{2}(x^{2}+1)z^{2}&\implies \mathrm{d}u = -(x^{2}+1)z\,\mathrm{d}z\\
    \int_{0}^{\infty}\exp\left(-\dfrac{1}{2}(x^{2}+1)z^{2}\right)z\,\mathrm{d}z &= -\dfrac{1}{x^{2}+1}\int_{0}^{-\infty}e^{u}\,\mathrm{d}u = \dfrac{1}{x^{2}+1}
  \end{split}
  \end{equation}
  Thus,
  \begin{equation}
    I^{2} = \int_{0}^{\infty}\dfrac{1}{x^{2}+1}\,\mathrm{d}x = \left.\dfrac{}{}\arctan x\right|_{0}^{\infty} = \dfrac{\pi}{2}\implies I = \sqrt{\dfrac{\pi}{2}}
  \end{equation}
}\end{problemAnswer}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------
% PROBLEM 5
%----------------------------------------------------------------------------------------
\begin{homeworkProblem}
  Let $X_1$, $X_2$ be two independent random variables each with p.d.f. $f_1(x)=e^{-x}$ for $x>0$ and $f_1(x)=0$ for $x \leq 0$. Let $Z = X_1 -X_2$ and $W=X_1/X_2$.

  (Notice that $\{Z=0\} = \{W=1\}$, but the conditional distribution of $X_1$ given $Z=0$ is not the same as the conditional distribution of given $W=1$. This discrepancy is known as the {\em Borel paradox} : The conditional p.d.f.'s are not like conditioning on events of probability 0. We can see that ``$Z$ is very close to $0$" is not the same as ``$W$ is very close to $1$".)

  (a) Prove that the conditional p.d.f of $X_1$ given $Z=0$ is
\[
 g_1(x_1 |0) = \left\{
 \begin{array}{ll}
 2 e^{-2x_1} & \mbox{$x_1 > 0$}, \\
 0 & \mbox{otherwise}.
 \end{array}
 \right.
\]\\
\begin{problemAnswer}{
  By the change of variable,
  \begin{equation}
  \begin{split}
    \begin{cases}
      X_{1}=X_{1}\\
      X_{2}= X_{1}-Z
    \end{cases} &\implies |J|=\left|\det \begin{pmatrix}
      1 & 0\\ 1 & -1
    \end{pmatrix}\right| = 1\\
    f_{X_{1},Z}(x_{1},z) &= e^{-2x_{1}+z}
  \end{split}
  \end{equation}
  For $Z$,
  \begin{equation}
  \begin{split}
    P(Z\leq z) &= P(X_{1}-X_{2}\leq z) = P(X_{2}\geq X_{1}-z)\\
    &= \begin{dcases}
      \displaystyle\int_{0}^{\infty}\int_{x_{1}-z}^{\infty}e^{-x_{1}-x_{2}}\,\mathrm{d}x_{2}\,\mathrm{d}x_{1}, &\text{if $z\leq 0$}\\
      1-\displaystyle\int_{z}^{\infty}\int_{0}^{x_{1}-z}e^{-x_{1}-x_{2}}\,\mathrm{d}x_{2}\,\mathrm{d}x_{1},&\text{if $z> 0$}
    \end{dcases}\\
    &= \begin{dcases}
      \dfrac{e^{z}}{2},&\text{if $z\leq 0$}\\
      1-\dfrac{e^{-z}}{2},&\text{if $z>0$}
    \end{dcases}\\
    f_{Z}(z) &= \dfrac{1}{2}e^{-|z|},\quad -\infty<z<\infty
  \end{split}
  \end{equation}
  Thus,
  \begin{equation}
    g_{1}(x_{1}\mid z) = 2 e^{-2x_{1}+z+|z|}\implies g_{1}(x_{1}\mid 0) = 2e^{-2x_{1}},\quad x_{1}>0 
  \end{equation}
}\end{problemAnswer}

(b) Prove that the conditional p.d.f. of $X_1$ given $W=1$ is
\[
 h_1 (x_1 | 1) = \left\{
 \begin{array}{ll}
 4 x_1 e^{-2x_1} & \mbox{$x_1 > 0$}, \\
 0 & \mbox{otherwise}.
 \end{array}
 \right.
\]
\\
\begin{problemAnswer}{
  By the change of variable,
  \begin{equation}
    \begin{split}
      \begin{dcases}
        X_{1}=X_{1}\\
        X_{2}=\dfrac{X_{1}}{W}
      \end{dcases} &\implies |J|=\left| \det \begin{pmatrix}
        1 & 0\\
        1/w & -x_{1}/w^{2}
      \end{pmatrix}\right| = \dfrac{x_{1}}{w^{2}}\\
      f_{X_{1},W}(x_{1},w) &= e^{-(1+1/w)x_{1}}\dfrac{x_{1}}{w^{2}}
    \end{split}
  \end{equation}
  and
  \begin{equation}
    P\left(\dfrac{X_{1}}{X_{2}}\leq w\right) = P\left(X_{2}\geq \dfrac{X_{1}}{w}\right) = \int_{0}^{\infty}\int_{x_{1}/w}^{\infty}e^{-x_{1}-x_{2}}\,\mathrm{d}x_{2}\,\mathrm{d}x_{1} = \dfrac{w}{w+1}\implies f_{W}(w) = \dfrac{1}{(1+w)^{2}}
  \end{equation}
  Thus,
  \begin{equation}
    h_{1}(x_{1}\mid w) = \left(\dfrac{w+1}{w}\right)^{2}x_{1}e^{-(1+1/w)x_{1}}\implies h_{1}(x_{1}\mid 1) = 4x_{1}e^{-2x_{1}},\quad x_{1}>0
  \end{equation}
}\end{problemAnswer}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------
% PROBLEM 6
%----------------------------------------------------------------------------------------
\begin{homeworkProblem}
Suppose that the random variable $K$ has a logarithmic series
distribution with parameter $\theta$ (where $0<\theta<1$), so that
\[ P(K=k) = \frac{\alpha\theta^k}{k}\qquad(k=1,2,\dots) \]
where $\alpha=-[\log(1-\theta)]^{-1}$. %and thus the probabilities are the
%terms in the series expansion of $-\alpha\log(1-\theta)$.  
Find the mean and variance of $K$.\\
\begin{problemAnswer}{
  \emph{(Method 1: Direct calculation)}

  \begin{equation}
  \begin{split}
    \operatorname{E}(K) &= \alpha\sum_{k=1}^{\infty}\theta^{k} = \dfrac{\alpha\theta}{1-\theta}\\
    \operatorname{E}(K^{2}) &= \alpha\sum_{k=1}^{\infty}k\theta^{k}=\alpha\theta\sum_{k=1}^{\infty}k\theta^{k-1}=\alpha\theta \sum_{k=1}^{\infty}\dfrac{d}{d\theta}\theta^{k}=\alpha\theta\cdot\dfrac{d}{d\theta}\dfrac{\theta}{1-\theta}=\dfrac{\alpha\theta}{(1-\theta)^{2}}\\
    \operatorname{Var}(K) &= \dfrac{\alpha\theta(1-\alpha\theta)}{(1-\theta)^{2}}
  \end{split}
  \end{equation}

  \emph{(Method 2: Probability generating function)}

  Recall that
  \begin{equation}
    \log(1-x) = -\sum_{k=1}^{\infty}\dfrac{x^{k}}{k}
  \end{equation}
  It follows that
  \begin{equation}
  \begin{split}
      \operatorname{E}(s^{X}) &= G_{K}(s) = \alpha\sum_{k=1}^{\infty}\dfrac{(s\theta)^{k}}{k} = -\alpha\log(1-s\theta)\\
      \operatorname{E}(K) &= G_{K}'(1) = -\left.\dfrac{\alpha \theta}{s\theta - 1}\right|_{s=1} = \dfrac{\alpha\theta}{1-\theta}\\
      \operatorname{Var}(K) &= G_{K}''(1)+G_{K}'(1)-\left\{G_{K}'(1)\right\}^{2}=\left.\dfrac{\alpha \theta^{2}}{(1-s\theta)^{2}}\right|_{s=1}+\dfrac{\alpha\theta}{1-\theta}-\left(\dfrac{\alpha\theta}{1-\theta}\right)^{2}\\
      &= \dfrac{\alpha\theta(1-\alpha\theta)}{(1-\theta)^{2}}\\
      (\because G_{K}^{(m)}(1) &= \operatorname{E}\left\{K(K-1)\cdots(K-m+1)\right\}\quad \text{(``$m$th factorial moment of $K$'')})
  \end{split}
  \end{equation}


  \emph{(Method 3: Moment generating function)}

  \begin{equation}
    \begin{split}
      \operatorname{E}(e^{tK}) &= M_{K}(t) = \alpha\sum_{k=1}^{\infty}\dfrac{(e^{t}\theta)^{k}}{k} = -\alpha \log(1-\theta e^{t})\\
      \operatorname{E}(K) &= M_{K}'(0) = -\left.\dfrac{\alpha\theta e^{t}}{\theta e^{t}-1}\right|_{t=0} = \dfrac{\alpha\theta}{1-\theta}\\
      \operatorname{E}(K^{2}) &= M_{K}''(0) = \left.\dfrac{\alpha\theta e^{t}}{(1-\theta e^{t})^{2}}\right|_{t=0} = \dfrac{\alpha\theta}{(1-\theta)^{2}}\\
      \operatorname{Var}(K) &= \dfrac{\alpha\theta(1-\alpha\theta)}{(1-\theta)^{2}}
    \end{split}
  \end{equation}

  \emph{(Method 4: Cumulant generating function)}

  \begin{equation}
    \begin{split}
      K(t) &= \log M_{K}(t) = \log(-\alpha\log(1-\theta e^{t}))\\
      \operatorname{E}(K) &= K'(0) = \left.\dfrac{\theta e^{t}}{(\theta e^{t}-1)\log(1-\theta e^{t})}\right|_{t=0} = \dfrac{-\theta}{(1-\theta)\log(1-\theta)} = \dfrac{\alpha\theta}{1-\theta}\;\;\left(\because \alpha = -\dfrac{1}{\log(1-\theta)}\right)\\
      \operatorname{Var}(K) &= K''(0) = \left.\dfrac{\theta e^{t}(\theta e^{t}+\log(1-\theta e^{t}))}{(\theta e^{t}-1)^{2}\left\{\log(1-\theta e^{t})\right\}^{2}}\right|_{t=0} = -\dfrac{\theta(\theta+\log(1-\theta))}{(\theta-1)^{2}\left\{\log(1-\theta)\right\}^{2}}\\
      &= -\dfrac{\alpha^{2}\theta(\theta-1/\alpha)}{(1-\theta)^{2}}=\dfrac{\alpha\theta(1-\alpha\theta)}{(1-\theta)^{2}}
    \end{split}
  \end{equation}
}\end{problemAnswer}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------
% PROBLEM 7
%----------------------------------------------------------------------------------------
\begin{homeworkProblem}
  A random variable $X$ is sub-Gaussian if there is some $c>0$ such that
\[
{\rm E}\left( e^{tX} \right) \leq e^{c^2 t^2/2}
\]
for all $t$. 

(a) Suppose that $X$ is sub-Gaussian. Show that ${\rm E}(X)=0$ and ${\rm Var}(X) \leq c^2$.\\
\begin{problemAnswer}{
  The inequality translates to
  \begin{equation}
    \sum_{k=0}^{\infty}\dfrac{t^{k}}{k!}\operatorname{E}(X^{k})\leq \sum_{k=0}^{\infty}\dfrac{c^{2k}t^{2k}}{2^{k}k!}
  \end{equation}
  Observe that up to the quadratic terms,
  \begin{equation}
    t\operatorname{E}(X)+\dfrac{t^{2}}{2}\operatorname{E}(X^{2})+o(t^{2}) \leq \dfrac{c^{2}t^{2}}{2}+o(t^{2})\quad \text{as }t\to 0
  \end{equation}
  Note that $f(t)\in o(t^{2}) \iff f(t)/t^{2}\to 0$ as $t\to 0$. Thus, for $t>0$, dividing by $t$,
  \begin{equation}
    \lim_{t\downarrow 0}\left(\operatorname{E}(X)+\dfrac{t}{2}\operatorname{E}(X^{2})+\dfrac{o(t^{2})}{t} \right)\leq \lim_{t\downarrow 0}\left(\dfrac{c^{2}t}{2}+\dfrac{o(t^{2})}{t}\right) \implies \operatorname{E}(X)\leq 0
  \end{equation}
  Again for $t< 0$, dividing by $t$,
  \begin{equation}
    \lim_{t\uparrow 0}\left(\operatorname{E}(X)+\dfrac{t}{2}\operatorname{E}(X^{2})+\dfrac{o(t^{2})}{t}\right)\geq \lim_{t\uparrow 0}\left(\dfrac{c^{2}t}{2}+\dfrac{o(t^{2})}{t}\right) \implies \operatorname{E}(X)\geq 0
  \end{equation}
  Thus, $\operatorname{E}(X)=0$.

  Now dividing both sides by $t^{2}$,
  \begin{equation}
    \lim_{t\to0}\dfrac{\operatorname{E}(X^{2})}{2}\leq \lim_{t\to0}\left(\dfrac{c^{2}}{2}+\dfrac{o(t^{2})}{t^{2}}\right)\implies \operatorname{Var}(X) \leq c^{2}
  \end{equation}
}\end{problemAnswer}

(b) Let $X \sim {\rm Unif}(0,1)$. Show that $X-1/2$ is sub-Gaussian and check if (a) holds under $X-1/2$. \\
\begin{problemAnswer}{
  \begin{equation}
    \operatorname{E}(e^{t(X-1/2)}) = \int_{0}^{1}e^{tx-t/2}\,\mathrm{d}x = \dfrac{e^{t/2}-e^{-t/2}}{t}
  \end{equation}
  Observe that
  \begin{equation}
    \begin{split}
      e^{t/2} &= \sum_{k=0}^{\infty}\dfrac{(t/2)^{k}}{k!}\\
      e^{-t/2} &= \sum_{k=0}^{\infty}\dfrac{(-1)^{k}(t/2)^{k}}{k!}\\
      e^{t/2}-e^{-t/2} &= 2\sum_{k=0}^{\infty}\dfrac{(t/2)^{2k+1}}{(2k+1)!}\\
      \operatorname{E}(e^{t(X-1/2)}) &= \sum_{k=0}^{\infty}\dfrac{(t/2)^{2k}}{(2k+1)!}\leq \sum_{k=0}^{\infty}\dfrac{(t/2)^{2k}}{k! 2^{k}}=\sum_{k=0}^{\infty}\dfrac{(t^{2}/8)^{k}}{k!}=e^{t^{2}/8} \qquad (\because (2k+1)! \geq k! 2^{k})
    \end{split}
  \end{equation}
  Thus, $X-1/2$ is sub-Gaussian and $c = 1/2$.
}\end{problemAnswer}
\end{homeworkProblem}


%----------------------------------------------------------------------------------------
% PROBLEM 8
%----------------------------------------------------------------------------------------
\begin{homeworkProblem}
  Let $X$ denote a random variable with a standard Laplace distribution with p.d.f
\[
 f(x) = \frac{1}{2} \exp\{-|x|\},~-\infty < x < \infty.
\]
Find the first, second and the third cumulants, i.e. $\kappa_1$, $\kappa_2$ and $\kappa_3$.\\
\begin{problemAnswer}{
  
}\end{problemAnswer}
\end{homeworkProblem}

%----------------------------------------------------------------------------------------
% PROBLEM 5
%----------------------------------------------------------------------------------------
% \begin{homeworkProblem}
% Let $(Y_1, Y_2)$ denote the coordinates of a point chosen at random inside a unit circle whose center is at the origin. That is, $Y_1$ and $Y_2$ have a joint density function given by
% \begin{align*}
%   f(y_1, y_2) = \begin{cases}
%     \frac{1}{\pi}, & y_1^2 + y_2^2 \le 1,\\
%     0, & \text{elsewhere.}
%   \end{cases}
% \end{align*}

% Find $P(Y_1 \le Y_2)$.\\

% \begin{problemAnswer} {
%   The problem is equivalent to calculating $P(Y_{1}-Y_{2}\leq 0)$ and since the integration region is a circle on the $xy$-plane, it is more comfortable to use the polar coordinate. The region satisfying
%   \begin{equation}
%     y_{1}\leq y_{2} \quad \text{and}\quad y_{1}^{2}+y_{2}^{2}\leq 1
%   \end{equation}
%   is the circle below the line $y_{2}=y_{1}$. Thus,
%   \begin{equation}
%   \begin{split}
%     P(Y_{1}\leq Y_{2}) &= \int_{-3\pi/4}^{\pi/4}\int_{0}^{1}\dfrac{r}{\pi}\,\mathrm{d}r\,\mathrm{d}\theta\\
%     &= \int_{-3\pi/4}^{\pi/4}\dfrac{1}{2\pi}\,\mathrm{d}\theta\\
%     &= \dfrac{1}{2}
%   \end{split}
%   \end{equation}
% }\end{problemAnswer}

% \end{homeworkProblem}

% %----------------------------------------------------------------------------------------
% % PROBLEM 6
% %----------------------------------------------------------------------------------------

% \begin{homeworkProblem}
% Let $(X,Y)$ have a uniform distribution over the unit square, i.e. the joint p.d.f. of $(X,Y)$ is given by
% \begin{align}
% 	f(x,y) = \begin{cases}
%     1 & 0\le x\le 1,\ 0\le y\le 1\\
%     0, & \text{otherwise}
%   \end{cases}
% \end{align}

% Find the moment generating function $Z=-\log(X)-\log(Y)$.

% \begin{problemAnswer} {
%   Note that the given function is the joint PDF of two independent standard uniform random variables, that is, $X,Y \overset{\text{iid}}{\sim}\operatorname{Unif}(0,1)$. Thus, we can use the relations
%   \begin{itemize}
%     \item $-\log U \sim \operatorname{Exp}(1)$ where $U\sim \operatorname{Unif}(0,1)$.
%     \begin{proof}
%       Let $g(u) = -\log u$. Then, $g^{-1}(x) = e^{-x}$. By the variable transformation,
%       \begin{equation}
%         f_{X}(x) = f_{U}(g^{-1}(x))\left|\dfrac{d g^{-1}(x)}{dx}\right| = e^{-x}
%       \end{equation}
%       which is the density of the exponential distribution with mean $1$.
%     \end{proof}
%     \item If $E_{1},E_{2}\overset{\text{iid}}{\sim}\operatorname{Exp}(1)$, $E_{1}+E_{2}\sim \operatorname{Gamma}(2,1)$.
%   \end{itemize}
%   Thus, the MGF of $Z \sim \operatorname{Gamma}(2,1)$ becomes
%   \begin{equation}
%     \begin{split}
%       \operatorname{E}(e^{tZ}) &= \int_{0}^{\infty}ze^{(t-1)z}\,\mathrm{d}z\\
%       &= \dfrac{1}{(t-1)^{2}},\quad t<1
%     \end{split}
%   \end{equation}
% }\end{problemAnswer}

% \end{homeworkProblem}
%------------------------------------
%\bibliographystyle{apalike}
%\bibliography{Hw1}
\end{document}